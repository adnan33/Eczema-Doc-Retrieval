{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "import  os\n",
    "import  json\n",
    "import  time\n",
    "import  random\n",
    "import  logging\n",
    "import  subprocess\n",
    "import  torch\n",
    "import  torch.nn.functional         as F\n",
    "import  torch.nn                    as nn\n",
    "import  numpy                       as np\n",
    "import  torch.optim                 as optim\n",
    "# import  cPickle                     as pickle\n",
    "import  pickle\n",
    "import  torch.autograd              as autograd\n",
    "from    tqdm                        import tqdm\n",
    "from    pprint                      import pprint\n",
    "from    gensim.models.keyedvectors  import KeyedVectors\n",
    "from    nltk.tokenize               import sent_tokenize\n",
    "from    difflib                     import SequenceMatcher\n",
    "import  re\n",
    "import  nltk\n",
    "import  math\n",
    "\n",
    "bioclean    = lambda t: re.sub('[.,?;*!%^&_+():-\\[\\]{}]', '', t.replace('\"', '').replace('/', '').replace('\\\\', '').replace(\"'\", '').strip().lower()).split()\n",
    "softmax     = lambda z: np.exp(z) / np.sum(np.exp(z))\n",
    "stopwords   = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bm25_metrics(avgdl=0., mean=0., deviation=0.):\n",
    "    if(avgdl == 0):\n",
    "        total_words = 0\n",
    "        total_docs  = 0\n",
    "        for dic in tqdm(train_docs):\n",
    "            sents = sent_tokenize(train_docs[dic]['title']) + sent_tokenize(train_docs[dic]['abstractText'])\n",
    "            for s in sents:\n",
    "                total_words += len(tokenize(s))\n",
    "                total_docs  += 1.\n",
    "        avgdl = float(total_words) / float(total_docs)\n",
    "        print('avgdl {} computed'.format(avgdl))\n",
    "    else:\n",
    "        print('avgdl {} provided'.format(avgdl))\n",
    "    #\n",
    "    if(mean == 0 and deviation==0):\n",
    "        BM25scores  = []\n",
    "        k1, b       = 1.2, 0.75\n",
    "        not_found   = 0\n",
    "        for qid in tqdm(bioasq7_data):\n",
    "            qtext           = bioasq7_data[qid]['body']\n",
    "            all_retr_ids    = [link.split('/')[-1] for link in bioasq7_data[qid]['documents']]\n",
    "            for dic in all_retr_ids:\n",
    "                try:\n",
    "                    sents   = sent_tokenize(train_docs[dic]['title']) + sent_tokenize(train_docs[dic]['abstractText'])\n",
    "                    q_toks  = tokenize(qtext)\n",
    "                    for sent in sents:\n",
    "                        BM25score = similarity_score(q_toks, tokenize(sent), k1, b, idf, avgdl, False, 0, 0, max_idf)\n",
    "                        BM25scores.append(BM25score)\n",
    "                except KeyError:\n",
    "                    not_found += 1\n",
    "        #\n",
    "        mean        = sum(BM25scores)/float(len(BM25scores))\n",
    "        nominator   = 0\n",
    "        for score in BM25scores:\n",
    "            nominator += ((score - mean) ** 2)\n",
    "        deviation   = math.sqrt((nominator) / float(len(BM25scores) - 1))\n",
    "        print('mean {} computed'.format(mean))\n",
    "        print('deviation {} computed'.format(deviation))\n",
    "    else:\n",
    "        print('mean {} provided'.format(mean))\n",
    "        print('deviation {} provided'.format(deviation))\n",
    "    return avgdl, mean, deviation\n",
    "\n",
    "# Compute the term frequency of a word for a specific document\n",
    "def tf(term, document):\n",
    "    tf = 0\n",
    "    for word in document:\n",
    "        if word == term:\n",
    "            tf += 1\n",
    "    if len(document) == 0:\n",
    "        return tf\n",
    "    else:\n",
    "        return tf/len(document)\n",
    "\n",
    "# Use BM25 ranking function in order to cimpute the similarity score between a question anda snippet\n",
    "# query: the given question\n",
    "# document: the snippet\n",
    "# k1, b: parameters\n",
    "# idf_scores: list with the idf scores\n",
    "# avddl: average document length\n",
    "# nomalize: in case we want to use Z-score normalization (Boolean)\n",
    "# mean, deviation: variables used for Z-score normalization\n",
    "def similarity_score(query, document, k1, b, idf_scores, avgdl, normalize, mean, deviation, rare_word):\n",
    "    score = 0\n",
    "    for query_term in query:\n",
    "        if query_term not in idf_scores:\n",
    "            score += rare_word * (\n",
    "                    (tf(query_term, document) * (k1 + 1)) /\n",
    "                    (\n",
    "                            tf(query_term, document) +\n",
    "                            k1 * (1 - b + b * (len(document) / avgdl))\n",
    "                    )\n",
    "            )\n",
    "        else:\n",
    "            score += idf_scores[query_term] * ((tf(query_term, document) * (k1 + 1)) / (tf(query_term, document) + k1 * (1 - b + b * (len(document) / avgdl))))\n",
    "    if normalize:\n",
    "        return ((score - mean)/deviation)\n",
    "    else:\n",
    "        return score\n",
    "\n",
    "# Compute the average length from a collection of documents\n",
    "def compute_avgdl(documents):\n",
    "    total_words = 0\n",
    "    for document in documents:\n",
    "        total_words += len(document)\n",
    "    avgdl = total_words / len(documents)\n",
    "    return avgdl\n",
    "\n",
    "def weighted_binary_cross_entropy(output, target, weights=None):\n",
    "    if weights is not None:\n",
    "        assert len(weights) == 2\n",
    "        loss = weights[1] * (target * torch.log(output)) + weights[0] * ((1 - target) * torch.log(1 - output))\n",
    "    else:\n",
    "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
    "    return torch.neg(torch.mean(loss))\n",
    "\n",
    "def RemoveTrainLargeYears(data, doc_text):\n",
    "  data['queries'] = [q for q in data['queries'] if (len(q['retrieved_documents']) > 0)]\n",
    "  for i in tqdm(range(len(data['queries']))):\n",
    "    hyear = 1900\n",
    "    for j in range(len(data['queries'][i]['retrieved_documents'])):\n",
    "      if data['queries'][i]['retrieved_documents'][j]['is_relevant']:\n",
    "        doc_id = data['queries'][i]['retrieved_documents'][j]['doc_id']\n",
    "        year = doc_text[doc_id]['publicationDate'].split('-')[0]\n",
    "        if year[:1] == '1' or year[:1] == '2':\n",
    "          if int(year) > hyear:\n",
    "            hyear = int(year)\n",
    "    # if(len(data['queries'][i]['retrieved_documents'])>0):\n",
    "    j = 0\n",
    "    while True:\n",
    "      doc_id    = data['queries'][i]['retrieved_documents'][j]['doc_id']\n",
    "      year      = doc_text[doc_id]['publicationDate'].split('-')[0]\n",
    "      if (year[:1] == '1' or year[:1] == '2') and int(year) > hyear:\n",
    "        del data['queries'][i]['retrieved_documents'][j]\n",
    "      else:\n",
    "        j += 1\n",
    "      if j == len(data['queries'][i]['retrieved_documents']):\n",
    "        break\n",
    "  return data\n",
    "\n",
    "def RemoveBadYears(data, doc_text, train):\n",
    "  for i in range(len(data['queries'])):\n",
    "    j = 0\n",
    "    while True:\n",
    "      doc_id    = data['queries'][i]['retrieved_documents'][j]['doc_id']\n",
    "      year      = doc_text[doc_id]['publicationDate'].split('-')[0]\n",
    "      ##########################\n",
    "      # Skip 2017/2018 docs always. Skip 2016 docs for training.\n",
    "      # Need to change for final model - 2017 should be a train year only.\n",
    "      # Use only for testing.\n",
    "      if year == '2017' or year == '2018' or (train and year == '2016'):\n",
    "      #if year == '2018' or (train and year == '2017'):\n",
    "        del data['queries'][i]['retrieved_documents'][j]\n",
    "      else:\n",
    "        j += 1\n",
    "      ##########################\n",
    "      if j == len(data['queries'][i]['retrieved_documents']):\n",
    "        break\n",
    "  return data\n",
    "\n",
    "def print_params(model):\n",
    "    '''\n",
    "    It just prints the number of parameters in the model.\n",
    "    :param model:   The pytorch model\n",
    "    :return:        Nothing.\n",
    "    '''\n",
    "    print(40 * '=')\n",
    "    print(model)\n",
    "    print(40 * '=')\n",
    "    logger.info(40 * '=')\n",
    "    logger.info(model)\n",
    "    logger.info(40 * '=')\n",
    "    trainable       = 0\n",
    "    untrainable     = 0\n",
    "    for parameter in model.parameters():\n",
    "        # print(parameter.size())\n",
    "        v = 1\n",
    "        for s in parameter.size():\n",
    "            v *= s\n",
    "        if(parameter.requires_grad):\n",
    "            trainable   += v\n",
    "        else:\n",
    "            untrainable += v\n",
    "    total_params = trainable + untrainable\n",
    "    print(40 * '=')\n",
    "    print('trainable:{} untrainable:{} total:{}'.format(trainable, untrainable, total_params))\n",
    "    print(40 * '=')\n",
    "    logger.info(40 * '=')\n",
    "    logger.info('trainable:{} untrainable:{} total:{}'.format(trainable, untrainable, total_params))\n",
    "    logger.info(40 * '=')\n",
    "\n",
    "def dummy_test():\n",
    "    doc1_embeds         = np.random.rand(40, 200)\n",
    "    doc2_embeds         = np.random.rand(30, 200)\n",
    "    question_embeds     = np.random.rand(20, 200)\n",
    "    q_idfs              = np.random.rand(20, 1)\n",
    "    gaf                 = np.random.rand(4)\n",
    "    baf                 = np.random.rand(4)\n",
    "    for epoch in range(200):\n",
    "        optimizer.zero_grad()\n",
    "        cost_, doc1_emit_, doc2_emit_ = model(\n",
    "            doc1_embeds     = doc1_embeds,\n",
    "            doc2_embeds     = doc2_embeds,\n",
    "            question_embeds = question_embeds,\n",
    "            q_idfs          = q_idfs,\n",
    "            gaf             = gaf,\n",
    "            baf             = baf\n",
    "        )\n",
    "        cost_.backward()\n",
    "        optimizer.step()\n",
    "        the_cost = cost_.cpu().item()\n",
    "        print(the_cost, float(doc1_emit_), float(doc2_emit_))\n",
    "    print(20 * '-')\n",
    "\n",
    "def compute_the_cost(costs, back_prop=True):\n",
    "    cost_ = torch.stack(costs)\n",
    "    cost_ = cost_.sum() / (1.0 * cost_.size(0))\n",
    "    if(back_prop):\n",
    "        cost_.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    the_cost = cost_.cpu().item()\n",
    "    return the_cost\n",
    "\n",
    "def save_checkpoint(epoch, model, max_dev_map, optimizer, filename='checkpoint.pth.tar'):\n",
    "    '''\n",
    "    :param state:       the stete of the pytorch mode\n",
    "    :param filename:    the name of the file in which we will store the model.\n",
    "    :return:            Nothing. It just saves the model.\n",
    "    '''\n",
    "    state = {\n",
    "        'epoch':            epoch,\n",
    "        'state_dict':       model.state_dict(),\n",
    "        'best_valid_score': max_dev_map,\n",
    "        'optimizer':        optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def get_map_res(fgold, femit):\n",
    "    logger.info(\"command:\")\n",
    "    logger.info(['python', eval_path, fgold, femit])\n",
    "    print(\"command:\")\n",
    "    print(['python', eval_path, fgold, femit])\n",
    "    trec_eval_res   = subprocess.Popen(['python', eval_path, fgold, femit], stdout=subprocess.PIPE, shell=False)\n",
    "    (out, err)      = trec_eval_res.communicate()\n",
    "    lines           = out.decode(\"utf-8\").split('\\n')\n",
    "    map_res         = [l for l in lines if (l.startswith('map '))][0].split('\\t')\n",
    "    map_res         = float(map_res[-1])\n",
    "    return map_res\n",
    "\n",
    "def back_prop(batch_costs, epoch_costs, batch_acc, epoch_acc):\n",
    "    batch_cost = sum(batch_costs) / float(len(batch_costs))\n",
    "    batch_cost.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    batch_aver_cost = batch_cost.cpu().item()\n",
    "    epoch_aver_cost = sum(epoch_costs) / float(len(epoch_costs))\n",
    "    batch_aver_acc  = sum(batch_acc) / float(len(batch_acc))\n",
    "    epoch_aver_acc  = sum(epoch_acc) / float(len(epoch_acc))\n",
    "    return batch_aver_cost, epoch_aver_cost, batch_aver_acc, epoch_aver_acc\n",
    "\n",
    "def get_bioasq_res(prefix, data_gold, data_emitted, data_for_revision):\n",
    "    '''\n",
    "    java -Xmx10G -cp /home/dpappas/for_ryan/bioasq6_eval/flat/BioASQEvaluation/dist/BioASQEvaluation.jar\n",
    "    evaluation.EvaluatorTask1b -phaseA -e 5\n",
    "    /home/dpappas/for_ryan/bioasq6_submit_files/test_batch_1/BioASQ-task6bPhaseB-testset1\n",
    "    ./drmm-experimental_submit.json\n",
    "    '''\n",
    "    jar_path = retrieval_jar_path\n",
    "    #\n",
    "    fgold   = '{}_data_for_revision.json'.format(prefix)\n",
    "    fgold   = os.path.join(odir, fgold)\n",
    "    fgold   = os.path.abspath(fgold)\n",
    "    with open(fgold, 'w') as f:\n",
    "        f.write(json.dumps(data_for_revision, indent=4, sort_keys=True))\n",
    "        f.close()\n",
    "    #\n",
    "    for tt in data_gold['questions']:\n",
    "        if ('exact_answer' in tt):\n",
    "            del (tt['exact_answer'])\n",
    "        if ('ideal_answer' in tt):\n",
    "            del (tt['ideal_answer'])\n",
    "        if ('type' in tt):\n",
    "            del (tt['type'])\n",
    "    fgold    = '{}_gold_bioasq.json'.format(prefix)\n",
    "    fgold   = os.path.join(odir, fgold)\n",
    "    fgold   = os.path.abspath(fgold)\n",
    "    with open(fgold, 'w') as f:\n",
    "        f.write(json.dumps(data_gold, indent=4, sort_keys=True))\n",
    "        f.close()\n",
    "    #\n",
    "    femit    = '{}_emit_bioasq.json'.format(prefix)\n",
    "    femit   = os.path.join(odir, femit)\n",
    "    femit   = os.path.abspath(femit)\n",
    "    with open(femit, 'w') as f:\n",
    "        f.write(json.dumps(data_emitted, indent=4, sort_keys=True))\n",
    "        f.close()\n",
    "    #\n",
    "    print('command:')\n",
    "    print([\n",
    "            'java', '-Xmx10G', '-cp', jar_path, 'evaluation.EvaluatorTask1b',\n",
    "            '-phaseA', '-e', '5', fgold, femit\n",
    "        ])\n",
    "    logger.info('command:')\n",
    "    logger.info([\n",
    "            'java', '-Xmx10G', '-cp', jar_path, 'evaluation.EvaluatorTask1b',\n",
    "            '-phaseA', '-e', '5', fgold, femit\n",
    "        ]\n",
    "    )\n",
    "    bioasq_eval_res = subprocess.Popen(\n",
    "        [\n",
    "            'java', '-Xmx10G', '-cp', jar_path, 'evaluation.EvaluatorTask1b',\n",
    "            '-phaseA', '-e', '5', fgold, femit\n",
    "        ],\n",
    "        stdout=subprocess.PIPE, shell=False\n",
    "    )\n",
    "    (out, err)  = bioasq_eval_res.communicate()\n",
    "    lines       = out.decode(\"utf-8\").split('\\n')\n",
    "    ret = {}\n",
    "    for line in lines:\n",
    "        if(':' in line):\n",
    "            k       = line.split(':')[0].strip()\n",
    "            v       = line.split(':')[1].strip()\n",
    "            ret[k]  = float(v)\n",
    "    return ret\n",
    "\n",
    "def similar(upstream_seq, downstream_seq):\n",
    "    upstream_seq    = upstream_seq.encode('ascii','ignore')\n",
    "    downstream_seq  = downstream_seq.encode('ascii','ignore')\n",
    "    s               = SequenceMatcher(None, upstream_seq, downstream_seq)\n",
    "    match           = s.find_longest_match(0, len(upstream_seq), 0, len(downstream_seq))\n",
    "    upstream_start  = match[0]\n",
    "    upstream_end    = match[0]+match[2]\n",
    "    longest_match   = upstream_seq[upstream_start:upstream_end]\n",
    "    to_match        = upstream_seq if(len(downstream_seq)>len(upstream_seq)) else downstream_seq\n",
    "    r1              = SequenceMatcher(None, to_match, longest_match).ratio()\n",
    "    return r1\n",
    "\n",
    "def get_pseudo_retrieved(dato):\n",
    "    some_ids = [item['document'].split('/')[-1].strip() for item in bioasq7_data[dato['query_id']]['snippets']]\n",
    "    pseudo_retrieved            = [\n",
    "        {\n",
    "            'bm25_score'        : 7.76,\n",
    "            'doc_id'            : id,\n",
    "            'is_relevant'       : True,\n",
    "            'norm_bm25_score'   : 3.85\n",
    "        }\n",
    "        for id in set(some_ids)\n",
    "    ]\n",
    "    return pseudo_retrieved\n",
    "\n",
    "def get_snippets_loss(good_sent_tags, gs_emits_, bs_emits_):\n",
    "    wright = torch.cat([gs_emits_[i] for i in range(len(good_sent_tags)) if (good_sent_tags[i] == 1)])\n",
    "    wrong  = [gs_emits_[i] for i in range(len(good_sent_tags)) if (good_sent_tags[i] == 0)]\n",
    "    wrong  = torch.cat(wrong + [bs_emits_.squeeze(-1)])\n",
    "    losses = [ model.my_hinge_loss(w.unsqueeze(0).expand_as(wrong), wrong) for w in wright]\n",
    "    return sum(losses) / float(len(losses))\n",
    "\n",
    "def get_two_snip_losses(good_sent_tags, gs_emits_, bs_emits_):\n",
    "    bs_emits_       = bs_emits_.squeeze(-1)\n",
    "    gs_emits_       = gs_emits_.squeeze(-1)\n",
    "    good_sent_tags  = torch.FloatTensor(good_sent_tags)\n",
    "    tags_2          = torch.zeros_like(bs_emits_)\n",
    "    if(use_cuda):\n",
    "        good_sent_tags  = good_sent_tags.cuda()\n",
    "        tags_2          = tags_2.cuda()\n",
    "    #\n",
    "    sn_d1_l         = F.binary_cross_entropy(gs_emits_, good_sent_tags, size_average=False, reduce=True)\n",
    "    sn_d2_l         = F.binary_cross_entropy(bs_emits_, tags_2,         size_average=False, reduce=True)\n",
    "    return sn_d1_l, sn_d2_l\n",
    "\n",
    "def init_the_logger(hdlr):\n",
    "    if not os.path.exists(odir):\n",
    "        os.makedirs(odir)\n",
    "    od          = odir.split('/')[-1] # 'sent_posit_drmm_MarginRankingLoss_0p001'\n",
    "    logger      = logging.getLogger(od)\n",
    "    if(hdlr is not None):\n",
    "        logger.removeHandler(hdlr)\n",
    "    hdlr        = logging.FileHandler(os.path.join(odir,'model.log'))\n",
    "    formatter   = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "    hdlr.setFormatter(formatter)\n",
    "    logger.addHandler(hdlr)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    return logger, hdlr\n",
    "\n",
    "def get_words(s, idf, max_idf):\n",
    "    sl  = tokenize(s)\n",
    "    sl  = [s for s in sl]\n",
    "    sl2 = [s for s in sl if idf_val(s, idf, max_idf) >= 2.0]\n",
    "    return sl, sl2\n",
    "\n",
    "def tokenize(x):\n",
    "  return bioclean(x)\n",
    "\n",
    "def idf_val(w, idf, max_idf):\n",
    "    if w in idf:\n",
    "        return idf[w]\n",
    "    return max_idf\n",
    "\n",
    "def get_embeds(tokens, wv):\n",
    "    ret1, ret2 = [], []\n",
    "    for tok in tokens:\n",
    "        if(tok in wv):\n",
    "            ret1.append(tok)\n",
    "            ret2.append(wv[tok])\n",
    "    return ret1, np.array(ret2, 'float64')\n",
    "\n",
    "def get_embeds_use_unk(tokens, wv):\n",
    "    ret1, ret2 = [], []\n",
    "    for tok in tokens:\n",
    "        if(tok in wv):\n",
    "            ret1.append(tok)\n",
    "            ret2.append(wv[tok])\n",
    "        else:\n",
    "            wv[tok] = np.random.randn(embedding_dim)\n",
    "            ret1.append(tok)\n",
    "            ret2.append(wv[tok])\n",
    "    return ret1, np.array(ret2, 'float64')\n",
    "\n",
    "def get_embeds_use_only_unk(tokens, wv):\n",
    "    ret1, ret2 = [], []\n",
    "    for tok in tokens:\n",
    "        wv[tok] = np.random.randn(embedding_dim)\n",
    "        ret1.append(tok)\n",
    "        ret2.append(wv[tok])\n",
    "    return ret1, np.array(ret2, 'float64')\n",
    "\n",
    "def load_idfs(idf_path, words):\n",
    "    print('Loading IDF tables')\n",
    "    #\n",
    "    # with open(dataloc + 'idf.pkl', 'rb') as f:\n",
    "    with open(idf_path, 'rb') as f:\n",
    "        idf = pickle.load(f)\n",
    "    ret = {}\n",
    "    for w in words:\n",
    "        if w in idf:\n",
    "            ret[w] = idf[w]\n",
    "    max_idf = 0.0\n",
    "    for w in idf:\n",
    "        if idf[w] > max_idf:\n",
    "            max_idf = idf[w]\n",
    "    idf = None\n",
    "    print('Loaded idf tables with max idf {}'.format(max_idf))\n",
    "    #\n",
    "    return ret, max_idf\n",
    "\n",
    "def uwords(words):\n",
    "  uw = {}\n",
    "  for w in words:\n",
    "    uw[w] = 1\n",
    "  return [w for w in uw]\n",
    "\n",
    "def ubigrams(words):\n",
    "  uw = {}\n",
    "  prevw = \"<pw>\"\n",
    "  for w in words:\n",
    "    uw[prevw + '_' + w] = 1\n",
    "    prevw = w\n",
    "  return [w for w in uw]\n",
    "\n",
    "def query_doc_overlap(qwords, dwords, idf, max_idf):\n",
    "    # % Query words in doc.\n",
    "    qwords_in_doc = 0\n",
    "    idf_qwords_in_doc = 0.0\n",
    "    idf_qwords = 0.0\n",
    "    for qword in uwords(qwords):\n",
    "      idf_qwords += idf_val(qword, idf, max_idf)\n",
    "      for dword in uwords(dwords):\n",
    "        if qword == dword:\n",
    "          idf_qwords_in_doc += idf_val(qword, idf, max_idf)\n",
    "          qwords_in_doc     += 1\n",
    "          break\n",
    "    if len(qwords) <= 0:\n",
    "      qwords_in_doc_val = 0.0\n",
    "    else:\n",
    "      qwords_in_doc_val = (float(qwords_in_doc) /\n",
    "                           float(len(uwords(qwords))))\n",
    "    if idf_qwords <= 0.0:\n",
    "      idf_qwords_in_doc_val = 0.0\n",
    "    else:\n",
    "      idf_qwords_in_doc_val = float(idf_qwords_in_doc) / float(idf_qwords)\n",
    "    # % Query bigrams  in doc.\n",
    "    qwords_bigrams_in_doc = 0\n",
    "    idf_qwords_bigrams_in_doc = 0.0\n",
    "    idf_bigrams = 0.0\n",
    "    for qword in ubigrams(qwords):\n",
    "      wrds = qword.split('_')\n",
    "      idf_bigrams += idf_val(wrds[0], idf, max_idf) * idf_val(wrds[1], idf, max_idf)\n",
    "      for dword in ubigrams(dwords):\n",
    "        if qword == dword:\n",
    "          qwords_bigrams_in_doc += 1\n",
    "          idf_qwords_bigrams_in_doc += (idf_val(wrds[0], idf, max_idf) * idf_val(wrds[1], idf, max_idf))\n",
    "          break\n",
    "    if len(qwords) <= 0:\n",
    "      qwords_bigrams_in_doc_val = 0.0\n",
    "    else:\n",
    "      qwords_bigrams_in_doc_val = (float(qwords_bigrams_in_doc) / float(len(ubigrams(qwords))))\n",
    "    if idf_bigrams <= 0.0:\n",
    "      idf_qwords_bigrams_in_doc_val = 0.0\n",
    "    else:\n",
    "      idf_qwords_bigrams_in_doc_val = (float(idf_qwords_bigrams_in_doc) / float(idf_bigrams))\n",
    "    return [\n",
    "        qwords_in_doc_val,\n",
    "        qwords_bigrams_in_doc_val,\n",
    "        idf_qwords_in_doc_val,\n",
    "        idf_qwords_bigrams_in_doc_val\n",
    "    ]\n",
    "\n",
    "def GetScores(qtext, dtext, bm25, idf, max_idf):\n",
    "    qwords, qw2 = get_words(qtext, idf, max_idf)\n",
    "    dwords, dw2 = get_words(dtext, idf, max_idf)\n",
    "    qd1         = query_doc_overlap(qwords, dwords, idf, max_idf)\n",
    "    bm25        = [bm25]\n",
    "    return qd1[0:3] + bm25\n",
    "\n",
    "def GetWords(data, doc_text, words):\n",
    "  for i in range(len(data['queries'])):\n",
    "    qwds = tokenize(data['queries'][i]['query_text'])\n",
    "    for w in qwds:\n",
    "      words[w] = 1\n",
    "    for j in range(len(data['queries'][i]['retrieved_documents'])):\n",
    "      doc_id = data['queries'][i]['retrieved_documents'][j]['doc_id']\n",
    "      dtext = (\n",
    "              doc_text[doc_id]['title'] + ' <title> ' + doc_text[doc_id]['abstractText']\n",
    "              # +\n",
    "              # ' '.join(\n",
    "              #     [\n",
    "              #         ' '.join(mm) for mm in\n",
    "              #         get_the_mesh(doc_text[doc_id])\n",
    "              #     ]\n",
    "              # )\n",
    "      )\n",
    "      dwds = tokenize(dtext)\n",
    "      for w in dwds:\n",
    "        words[w] = 1\n",
    "\n",
    "def get_gold_snips(quest_id, bioasq6_data):\n",
    "    gold_snips                  = []\n",
    "    if ('snippets' in bioasq6_data[quest_id]):\n",
    "        for sn in bioasq6_data[quest_id]['snippets']:\n",
    "            gold_snips.extend(sent_tokenize(sn['text']))\n",
    "    return list(set(gold_snips))\n",
    "\n",
    "def prep_extracted_snippets(extracted_snippets, docs, qid, top10docs, quest_body):\n",
    "    ret = {\n",
    "        'body'      : quest_body,\n",
    "        'documents' : top10docs,\n",
    "        'id'        : qid,\n",
    "        'snippets'  : [],\n",
    "    }\n",
    "    for esnip in extracted_snippets:\n",
    "        pid         = esnip[2].split('/')[-1]\n",
    "        the_text    = esnip[3]\n",
    "        esnip_res = {\n",
    "            # 'score'     : esnip[1],\n",
    "            \"document\"  : \"http://www.ncbi.nlm.nih.gov/pubmed/{}\".format(pid),\n",
    "            \"text\"      : the_text\n",
    "        }\n",
    "        try:\n",
    "            ind_from                            = docs[pid]['title'].index(the_text)\n",
    "            ind_to                              = ind_from + len(the_text)\n",
    "            esnip_res[\"beginSection\"]           = \"title\"\n",
    "            esnip_res[\"endSection\"]             = \"title\"\n",
    "            esnip_res[\"offsetInBeginSection\"]   = ind_from\n",
    "            esnip_res[\"offsetInEndSection\"]     = ind_to\n",
    "        except:\n",
    "            # print(the_text)\n",
    "            # pprint(docs[pid])\n",
    "            ind_from                            = docs[pid]['abstractText'].index(the_text)\n",
    "            ind_to                              = ind_from + len(the_text)\n",
    "            esnip_res[\"beginSection\"]           = \"abstract\"\n",
    "            esnip_res[\"endSection\"]             = \"abstract\"\n",
    "            esnip_res[\"offsetInBeginSection\"]   = ind_from\n",
    "            esnip_res[\"offsetInEndSection\"]     = ind_to\n",
    "        ret['snippets'].append(esnip_res)\n",
    "    return ret\n",
    "\n",
    "def get_snips(quest_id, gid, bioasq6_data):\n",
    "    good_snips = []\n",
    "    if('snippets' in bioasq6_data[quest_id]):\n",
    "        for sn in bioasq6_data[quest_id]['snippets']:\n",
    "            if(sn['document'].endswith(gid)):\n",
    "                good_snips.extend(sent_tokenize(sn['text']))\n",
    "    return good_snips\n",
    "\n",
    "def get_the_mesh(the_doc):\n",
    "    good_meshes = []\n",
    "    if('meshHeadingsList' in the_doc):\n",
    "        for t in the_doc['meshHeadingsList']:\n",
    "            t = t.split(':', 1)\n",
    "            t = t[1].strip()\n",
    "            t = t.lower()\n",
    "            good_meshes.append(t)\n",
    "    elif('MeshHeadings' in the_doc):\n",
    "        for mesh_head_set in the_doc['MeshHeadings']:\n",
    "            for item in mesh_head_set:\n",
    "                good_meshes.append(item['text'].strip().lower())\n",
    "    if('Chemicals' in the_doc):\n",
    "        for t in the_doc['Chemicals']:\n",
    "            t = t['NameOfSubstance'].strip().lower()\n",
    "            good_meshes.append(t)\n",
    "    good_mesh = sorted(good_meshes)\n",
    "    good_mesh = ['mesh'] + good_mesh\n",
    "    # good_mesh = ' # '.join(good_mesh)\n",
    "    # good_mesh = good_mesh.split()\n",
    "    # good_mesh = [gm.split() for gm in good_mesh]\n",
    "    good_mesh = [gm for gm in good_mesh]\n",
    "    return good_mesh\n",
    "\n",
    "def snip_is_relevant(one_sent, gold_snips):\n",
    "    # print one_sent\n",
    "    # pprint(gold_snips)\n",
    "    return int(\n",
    "        any(\n",
    "            [\n",
    "                (one_sent.encode('ascii', 'ignore')  in gold_snip.encode('ascii','ignore'))\n",
    "                or\n",
    "                (gold_snip.encode('ascii', 'ignore') in one_sent.encode('ascii','ignore'))\n",
    "                for gold_snip in gold_snips\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "def prep_data(quest, the_doc, the_bm25, wv, good_snips, idf, max_idf, use_sent_tokenizer):\n",
    "    if(use_sent_tokenizer):\n",
    "        good_sents  = sent_tokenize(the_doc['title']) + sent_tokenize(the_doc['abstractText'])\n",
    "    else:\n",
    "        good_sents  = [the_doc['title'] + the_doc['abstractText']]\n",
    "    ####\n",
    "    quest_toks      = tokenize(quest)\n",
    "    good_doc_af     = GetScores(quest, the_doc['title'] + the_doc['abstractText'], the_bm25, idf, max_idf)\n",
    "    good_doc_af.append(len(good_sents) / 60.)\n",
    "    #\n",
    "    doc_toks            = tokenize(the_doc['title'] + the_doc['abstractText'])\n",
    "    tomi                = (set(doc_toks) & set(quest_toks))\n",
    "    tomi_no_stop        = tomi - set(stopwords)\n",
    "    BM25score           = similarity_score(quest_toks, doc_toks, 1.2, 0.75, idf, avgdl, True, mean, deviation, max_idf)\n",
    "    tomi_no_stop_idfs   = [idf_val(w, idf, max_idf) for w in tomi_no_stop]\n",
    "    tomi_idfs           = [idf_val(w, idf, max_idf) for w in tomi]\n",
    "    quest_idfs          = [idf_val(w, idf, max_idf) for w in quest_toks]\n",
    "    features            = [\n",
    "        len(quest)                                      / 300.,\n",
    "        len(the_doc['title'] + the_doc['abstractText']) / 300.,\n",
    "        len(tomi_no_stop)                               / 100.,\n",
    "        BM25score,\n",
    "        sum(tomi_no_stop_idfs)                          / 100.,\n",
    "        sum(tomi_idfs)                                  / sum(quest_idfs),\n",
    "    ]\n",
    "    good_doc_af.extend(features)\n",
    "    ####\n",
    "    good_sents_embeds, good_sents_escores, held_out_sents, good_sent_tags = [], [], [], []\n",
    "    for good_text in good_sents:\n",
    "        sent_toks                   = tokenize(good_text)\n",
    "        good_tokens, good_embeds    = get_embeds(sent_toks, wv)\n",
    "        good_escores                = GetScores(quest, good_text, the_bm25, idf, max_idf)[:-1]\n",
    "        good_escores.append(len(sent_toks)/ 342.)\n",
    "        if (len(good_embeds) > 0):\n",
    "            #\n",
    "            tomi                = (set(sent_toks) & set(quest_toks))\n",
    "            tomi_no_stop        = tomi - set(stopwords)\n",
    "            BM25score           = similarity_score(quest_toks, sent_toks, 1.2, 0.75, idf, avgdl, True, mean, deviation, max_idf)\n",
    "            tomi_no_stop_idfs   = [idf_val(w, idf, max_idf) for w in tomi_no_stop]\n",
    "            tomi_idfs           = [idf_val(w, idf, max_idf) for w in tomi]\n",
    "            quest_idfs          = [idf_val(w, idf, max_idf) for w in quest_toks]\n",
    "            features            = [\n",
    "                len(quest)              / 300.,\n",
    "                len(good_text)          / 300.,\n",
    "                len(tomi_no_stop)       / 100.,\n",
    "                BM25score,\n",
    "                sum(tomi_no_stop_idfs)  / 100.,\n",
    "                sum(tomi_idfs)          / sum(quest_idfs),\n",
    "            ]\n",
    "            #\n",
    "            good_sents_embeds.append(good_embeds)\n",
    "            good_sents_escores.append(good_escores+features)\n",
    "            held_out_sents.append(good_text)\n",
    "            good_sent_tags.append(snip_is_relevant(' '.join(bioclean(good_text)), good_snips))\n",
    "    ####\n",
    "    return {\n",
    "        'sents_embeds'     : good_sents_embeds,\n",
    "        'sents_escores'    : good_sents_escores,\n",
    "        'doc_af'           : good_doc_af,\n",
    "        'sent_tags'        : good_sent_tags,\n",
    "        'held_out_sents'   : held_out_sents,\n",
    "    }\n",
    "\n",
    "def train_data_step1(train_data):\n",
    "    ret = []\n",
    "    for dato in tqdm(train_data['queries']):\n",
    "        quest       = dato['query_text']\n",
    "        quest_id    = dato['query_id']\n",
    "        bm25s       = {t['doc_id']: t['norm_bm25_score'] for t in dato[u'retrieved_documents']}\n",
    "        ret_pmids   = [t[u'doc_id'] for t in dato[u'retrieved_documents']]\n",
    "        good_pmids  = [t for t in ret_pmids if t in dato[u'relevant_documents']]\n",
    "        bad_pmids   = [t for t in ret_pmids if t not in dato[u'relevant_documents']]\n",
    "        if(len(bad_pmids)>0):\n",
    "            for gid in good_pmids:\n",
    "                bid = random.choice(bad_pmids)\n",
    "                ret.append((quest, quest_id, gid, bid, bm25s[gid], bm25s[bid]))\n",
    "    print('')\n",
    "    return ret\n",
    "\n",
    "def train_data_step2(instances, docs, wv, bioasq6_data, idf, max_idf, use_sent_tokenizer):\n",
    "    for quest_text, quest_id, gid, bid, bm25s_gid, bm25s_bid in instances:\n",
    "        if(use_sent_tokenizer):\n",
    "            good_snips              = get_snips(quest_id, gid, bioasq6_data)\n",
    "            good_snips              = [' '.join(bioclean(sn)) for sn in good_snips]\n",
    "        else:\n",
    "            good_snips              = []\n",
    "        #\n",
    "        datum                       = prep_data(quest_text, docs[gid], bm25s_gid, wv, good_snips, idf, max_idf, use_sent_tokenizer)\n",
    "        good_sents_embeds           = datum['sents_embeds']\n",
    "        good_sents_escores          = datum['sents_escores']\n",
    "        good_doc_af                 = datum['doc_af']\n",
    "        good_sent_tags              = datum['sent_tags']\n",
    "        good_held_out_sents         = datum['held_out_sents']\n",
    "        #\n",
    "        datum                       = prep_data(quest_text, docs[bid], bm25s_bid, wv, [], idf, max_idf, use_sent_tokenizer)\n",
    "        bad_sents_embeds            = datum['sents_embeds']\n",
    "        bad_sents_escores           = datum['sents_escores']\n",
    "        bad_doc_af                  = datum['doc_af']\n",
    "        bad_sent_tags               = [0] * len(datum['sent_tags'])\n",
    "        bad_held_out_sents          = datum['held_out_sents']\n",
    "        #\n",
    "        quest_tokens, quest_embeds  = get_embeds(tokenize(quest_text), wv)\n",
    "        q_idfs                      = np.array([[idf_val(qw, idf, max_idf)] for qw in quest_tokens], 'float')\n",
    "        #\n",
    "        if(use_sent_tokenizer == False or sum(good_sent_tags)>0):\n",
    "            yield {\n",
    "                'good_sents_embeds'     : good_sents_embeds,\n",
    "                'good_sents_escores'    : good_sents_escores,\n",
    "                'good_doc_af'           : good_doc_af,\n",
    "                'good_sent_tags'        : good_sent_tags,\n",
    "                'good_held_out_sents'   : good_held_out_sents,\n",
    "                #\n",
    "                'bad_sents_embeds'      : bad_sents_embeds,\n",
    "                'bad_sents_escores'     : bad_sents_escores,\n",
    "                'bad_doc_af'            : bad_doc_af,\n",
    "                'bad_sent_tags'         : bad_sent_tags,\n",
    "                'bad_held_out_sents'    : bad_held_out_sents,\n",
    "                #\n",
    "                'quest_embeds'          : quest_embeds,\n",
    "                'q_idfs'                : q_idfs,\n",
    "            }\n",
    "\n",
    "def train_one(epoch, bioasq6_data, two_losses, use_sent_tokenizer):\n",
    "    model.train()\n",
    "    batch_costs, batch_acc, epoch_costs, epoch_acc = [], [], [], []\n",
    "    batch_counter, epoch_aver_cost, epoch_aver_acc = 0, 0., 0.\n",
    "    #\n",
    "    train_instances = train_data_step1(train_data)\n",
    "    random.shuffle(train_instances)\n",
    "    #\n",
    "    start_time      = time.time()\n",
    "    pbar = tqdm(\n",
    "        iterable    = train_data_step2(train_instances, train_docs, wv, bioasq6_data, idf, max_idf, use_sent_tokenizer),\n",
    "        total       = 14288 # 17850\n",
    "    )\n",
    "    for datum in pbar:\n",
    "        cost_, doc1_emit_, doc2_emit_, gs_emits_, bs_emits_ = model(\n",
    "            doc1_sents_embeds   = datum['good_sents_embeds'],\n",
    "            doc2_sents_embeds   = datum['bad_sents_embeds'],\n",
    "            question_embeds     = datum['quest_embeds'],\n",
    "            q_idfs              = datum['q_idfs'],\n",
    "            sents_gaf           = datum['good_sents_escores'],\n",
    "            sents_baf           = datum['bad_sents_escores'],\n",
    "            doc_gaf             = datum['good_doc_af'],\n",
    "            doc_baf             = datum['bad_doc_af']\n",
    "        )\n",
    "        #\n",
    "        good_sent_tags, bad_sent_tags       = datum['good_sent_tags'], datum['bad_sent_tags']\n",
    "        if(two_losses):\n",
    "            sn_d1_l, sn_d2_l                = get_two_snip_losses(good_sent_tags, gs_emits_, bs_emits_)\n",
    "            snip_loss                       = sn_d1_l + sn_d2_l\n",
    "            # snip_loss = sn_d1_l\n",
    "            l                               = 0.5\n",
    "            cost_                           = ((1 - l) * snip_loss) + (l * cost_)\n",
    "        #\n",
    "        batch_acc.append(float(doc1_emit_ > doc2_emit_))\n",
    "        epoch_acc.append(float(doc1_emit_ > doc2_emit_))\n",
    "        epoch_costs.append(cost_.cpu().item())\n",
    "        batch_costs.append(cost_)\n",
    "        if (len(batch_costs) == b_size):\n",
    "            batch_counter += 1\n",
    "            batch_aver_cost, epoch_aver_cost, batch_aver_acc, epoch_aver_acc = back_prop(batch_costs, epoch_costs, batch_acc, epoch_acc)\n",
    "            elapsed_time    = time.time() - start_time\n",
    "            start_time      = time.time()\n",
    "            pbar.set_description(\n",
    "                '{:03d} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f}'.format(batch_counter, batch_aver_cost, epoch_aver_cost,\n",
    "                                                                   batch_aver_acc, epoch_aver_acc, elapsed_time))\n",
    "            logger.info('{:03d} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f}'.format( batch_counter, batch_aver_cost, epoch_aver_cost, batch_aver_acc, epoch_aver_acc, elapsed_time))\n",
    "            batch_costs, batch_acc = [], []\n",
    "    if (len(batch_costs) > 0):\n",
    "        batch_counter += 1\n",
    "        batch_aver_cost, epoch_aver_cost, batch_aver_acc, epoch_aver_acc = back_prop(batch_costs, epoch_costs, batch_acc, epoch_acc)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        print('{:03d} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f}'.format(batch_counter, batch_aver_cost, epoch_aver_cost, batch_aver_acc, epoch_aver_acc, elapsed_time))\n",
    "        logger.info('{:03d} {:.4f} {:.4f} {:.4f} {:.4f} {:.4f}'.format(batch_counter, batch_aver_cost, epoch_aver_cost, batch_aver_acc, epoch_aver_acc, elapsed_time))\n",
    "    print('Epoch:{:02d} aver_epoch_cost: {:.4f} aver_epoch_acc: {:.4f}'.format(epoch, epoch_aver_cost, epoch_aver_acc))\n",
    "    logger.info('Epoch:{:02d} aver_epoch_cost: {:.4f} aver_epoch_acc: {:.4f}'.format(epoch, epoch_aver_cost, epoch_aver_acc))\n",
    "\n",
    "def do_for_one_retrieved(doc_emit_, gs_emits_, held_out_sents, retr, doc_res, gold_snips):\n",
    "    emition                 = doc_emit_.cpu().item()\n",
    "    emitss                  = gs_emits_.tolist()\n",
    "    mmax                    = max(emitss)\n",
    "    all_emits, extracted_from_one = [], []\n",
    "    for ind in range(len(emitss)):\n",
    "        t = (\n",
    "            snip_is_relevant(held_out_sents[ind], gold_snips),\n",
    "            emitss[ind],\n",
    "            \"http://www.ncbi.nlm.nih.gov/pubmed/{}\".format(retr['doc_id']),\n",
    "            held_out_sents[ind]\n",
    "        )\n",
    "        all_emits.append(t)\n",
    "        # if(emitss[ind] == mmax):\n",
    "        #     extracted_from_one.append(t)\n",
    "        extracted_from_one.append(t)\n",
    "    doc_res[retr['doc_id']] = float(emition)\n",
    "    all_emits               = sorted(all_emits, key=lambda x: x[1], reverse=True)\n",
    "    return doc_res, extracted_from_one, all_emits\n",
    "\n",
    "def get_norm_doc_scores(the_doc_scores):\n",
    "    ks = list(the_doc_scores.keys())\n",
    "    vs = [the_doc_scores[k] for k in ks]\n",
    "    vs = softmax(vs)\n",
    "    norm_doc_scores = {}\n",
    "    for i in range(len(ks)):\n",
    "        norm_doc_scores[ks[i]] = vs[i]\n",
    "    return norm_doc_scores\n",
    "\n",
    "def select_snippets_v1(extracted_snippets):\n",
    "    '''\n",
    "    :param extracted_snippets:\n",
    "    :param doc_res:\n",
    "    :return: returns the best 10 snippets of all docs (0..n from each doc)\n",
    "    '''\n",
    "    sorted_snips = sorted(extracted_snippets, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_snips[:10]\n",
    "\n",
    "def select_snippets_v2(extracted_snippets):\n",
    "    '''\n",
    "    :param extracted_snippets:\n",
    "    :param doc_res:\n",
    "    :return: returns the best snippet of each doc  (1 from each doc)\n",
    "    '''\n",
    "    # is_relevant, the_sent_score, ncbi_pmid_link, the_actual_sent_text\n",
    "    ret                 = {}\n",
    "    for es in extracted_snippets:\n",
    "        if(es[2] in ret):\n",
    "            if(es[1] > ret[es[2]][1]):\n",
    "                ret[es[2]] = es\n",
    "        else:\n",
    "            ret[es[2]] = es\n",
    "    sorted_snips =  sorted(ret.values(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_snips[:10]\n",
    "\n",
    "def select_snippets_v3(extracted_snippets, the_doc_scores):\n",
    "    '''\n",
    "    :param      extracted_snippets:\n",
    "    :param      doc_res:\n",
    "    :return:    returns the top 10 snippets across all documents (0..n from each doc)\n",
    "    '''\n",
    "    norm_doc_scores     = get_norm_doc_scores(the_doc_scores)\n",
    "    # is_relevant, the_sent_score, ncbi_pmid_link, the_actual_sent_text\n",
    "    extracted_snippets  = [tt for tt in extracted_snippets if (tt[2] in norm_doc_scores)]\n",
    "    sorted_snips        = sorted(extracted_snippets, key=lambda x: x[1] * norm_doc_scores[x[2]], reverse=True)\n",
    "    return sorted_snips[:10]\n",
    "\n",
    "def do_for_some_retrieved(docs, dato, retr_docs, data_for_revision, ret_data, use_sent_tokenizer):\n",
    "    emitions                    = {\n",
    "        'body': dato['query_text'],\n",
    "        'id': dato['query_id'],\n",
    "        'documents': []\n",
    "    }\n",
    "    #\n",
    "    quest_text                  = dato['query_text']\n",
    "    #\n",
    "    quest_tokens, quest_embeds  = get_embeds(tokenize(quest_text), wv)\n",
    "    q_idfs                      = np.array([[idf_val(qw, idf, max_idf)] for qw in quest_tokens], 'float')\n",
    "    gold_snips                  = get_gold_snips(dato['query_id'], bioasq7_data)\n",
    "    #\n",
    "    doc_res, extracted_snippets         = {}, []\n",
    "    extracted_snippets_known_rel_num    = []\n",
    "    for retr in retr_docs:\n",
    "        datum                   = prep_data(quest_text, docs[retr['doc_id']], retr['norm_bm25_score'], wv, gold_snips, idf, max_idf, use_sent_tokenizer=use_sent_tokenizer)\n",
    "        doc_emit_, gs_emits_    = model.emit_one(\n",
    "            doc1_sents_embeds   = datum['sents_embeds'],\n",
    "            question_embeds     = quest_embeds,\n",
    "            q_idfs              = q_idfs,\n",
    "            sents_gaf           = datum['sents_escores'],\n",
    "            doc_gaf             = datum['doc_af']\n",
    "        )\n",
    "        doc_res, extracted_from_one, all_emits = do_for_one_retrieved(\n",
    "            doc_emit_, gs_emits_, datum['held_out_sents'], retr, doc_res, gold_snips\n",
    "        )\n",
    "        # is_relevant, the_sent_score, ncbi_pmid_link, the_actual_sent_text\n",
    "        extracted_snippets.extend(extracted_from_one)\n",
    "        #\n",
    "        total_relevant = sum([1 for em in all_emits if(em[0]==True)])\n",
    "        if (total_relevant > 0):\n",
    "            extracted_snippets_known_rel_num.extend(all_emits[:total_relevant])\n",
    "        if (dato['query_id'] not in data_for_revision):\n",
    "            data_for_revision[dato['query_id']] = {'query_text': dato['query_text'], 'snippets'  : {retr['doc_id']: all_emits}}\n",
    "        else:\n",
    "            data_for_revision[dato['query_id']]['snippets'][retr['doc_id']] = all_emits\n",
    "    #\n",
    "    doc_res                                 = sorted(doc_res.items(), key=lambda x: x[1], reverse=True)\n",
    "    the_doc_scores                          = dict([(\"http://www.ncbi.nlm.nih.gov/pubmed/{}\".format(pm[0]), pm[1]) for pm in doc_res[:10]])\n",
    "    doc_res                                 = [\"http://www.ncbi.nlm.nih.gov/pubmed/{}\".format(pm[0]) for pm in doc_res]\n",
    "    emitions['documents']                   = doc_res[:100]\n",
    "    ret_data['questions'].append(emitions)\n",
    "    #\n",
    "    extracted_snippets                      = [tt for tt in extracted_snippets if (tt[2] in doc_res[:10])]\n",
    "    extracted_snippets_known_rel_num        = [tt for tt in extracted_snippets_known_rel_num if (tt[2] in doc_res[:10])]\n",
    "    if(use_sent_tokenizer):\n",
    "        extracted_snippets_v1               = select_snippets_v1(extracted_snippets)\n",
    "        extracted_snippets_v2               = select_snippets_v2(extracted_snippets)\n",
    "        extracted_snippets_v3               = select_snippets_v3(extracted_snippets, the_doc_scores)\n",
    "        extracted_snippets_known_rel_num_v1 = select_snippets_v1(extracted_snippets_known_rel_num)\n",
    "        extracted_snippets_known_rel_num_v2 = select_snippets_v2(extracted_snippets_known_rel_num)\n",
    "        extracted_snippets_known_rel_num_v3 = select_snippets_v3(extracted_snippets_known_rel_num, the_doc_scores)\n",
    "    else:\n",
    "        extracted_snippets_v1, extracted_snippets_v2, extracted_snippets_v3 = [], [], []\n",
    "        extracted_snippets_known_rel_num_v1, extracted_snippets_known_rel_num_v2, extracted_snippets_known_rel_num_v3 = [], [], []\n",
    "    #\n",
    "    # pprint(extracted_snippets_v1)\n",
    "    # pprint(extracted_snippets_v2)\n",
    "    # pprint(extracted_snippets_v3)\n",
    "    # exit()\n",
    "    snips_res_v1                = prep_extracted_snippets(extracted_snippets_v1, docs, dato['query_id'], doc_res[:10], dato['query_text'])\n",
    "    snips_res_v2                = prep_extracted_snippets(extracted_snippets_v2, docs, dato['query_id'], doc_res[:10], dato['query_text'])\n",
    "    snips_res_v3                = prep_extracted_snippets(extracted_snippets_v3, docs, dato['query_id'], doc_res[:10], dato['query_text'])\n",
    "    # pprint(snips_res_v1)\n",
    "    # pprint(snips_res_v2)\n",
    "    # pprint(snips_res_v3)\n",
    "    # exit()\n",
    "    #\n",
    "    snips_res_known_rel_num_v1  = prep_extracted_snippets(extracted_snippets_known_rel_num_v1, docs, dato['query_id'], doc_res[:10], dato['query_text'])\n",
    "    snips_res_known_rel_num_v2  = prep_extracted_snippets(extracted_snippets_known_rel_num_v2, docs, dato['query_id'], doc_res[:10], dato['query_text'])\n",
    "    snips_res_known_rel_num_v3  = prep_extracted_snippets(extracted_snippets_known_rel_num_v3, docs, dato['query_id'], doc_res[:10], dato['query_text'])\n",
    "    #\n",
    "    snips_res = {\n",
    "        'v1' : snips_res_v1,\n",
    "        'v2' : snips_res_v2,\n",
    "        'v3' : snips_res_v3,\n",
    "    }\n",
    "    snips_res_known = {\n",
    "        'v1' : snips_res_known_rel_num_v1,\n",
    "        'v2' : snips_res_known_rel_num_v2,\n",
    "        'v3' : snips_res_known_rel_num_v3,\n",
    "    }\n",
    "    return data_for_revision, ret_data, snips_res, snips_res_known\n",
    "\n",
    "def print_the_results(prefix, all_bioasq_gold_data, all_bioasq_subm_data, all_bioasq_subm_data_known, data_for_revision):\n",
    "    bioasq_snip_res = get_bioasq_res(prefix, all_bioasq_gold_data, all_bioasq_subm_data_known, data_for_revision)\n",
    "    pprint(bioasq_snip_res)\n",
    "    print('{} known MAP documents: {}'.format(prefix, bioasq_snip_res['MAP documents']))\n",
    "    print('{} known F1 snippets: {}'.format(prefix, bioasq_snip_res['MF1 snippets']))\n",
    "    print('{} known MAP snippets: {}'.format(prefix, bioasq_snip_res['MAP snippets']))\n",
    "    print('{} known GMAP snippets: {}'.format(prefix, bioasq_snip_res['GMAP snippets']))\n",
    "    logger.info('{} known MAP documents: {}'.format(prefix, bioasq_snip_res['MAP documents']))\n",
    "    logger.info('{} known F1 snippets: {}'.format(prefix, bioasq_snip_res['MF1 snippets']))\n",
    "    logger.info('{} known MAP snippets: {}'.format(prefix, bioasq_snip_res['MAP snippets']))\n",
    "    logger.info('{} known GMAP snippets: {}'.format(prefix, bioasq_snip_res['GMAP snippets']))\n",
    "    #\n",
    "    bioasq_snip_res = get_bioasq_res(prefix, all_bioasq_gold_data, all_bioasq_subm_data, data_for_revision)\n",
    "    pprint(bioasq_snip_res)\n",
    "    print('{} MAP documents: {}'.format(prefix, bioasq_snip_res['MAP documents']))\n",
    "    print('{} F1 snippets: {}'.format(prefix, bioasq_snip_res['MF1 snippets']))\n",
    "    print('{} MAP snippets: {}'.format(prefix, bioasq_snip_res['MAP snippets']))\n",
    "    print('{} GMAP snippets: {}'.format(prefix, bioasq_snip_res['GMAP snippets']))\n",
    "    logger.info('{} MAP documents: {}'.format(prefix, bioasq_snip_res['MAP documents']))\n",
    "    logger.info('{} F1 snippets: {}'.format(prefix, bioasq_snip_res['MF1 snippets']))\n",
    "    logger.info('{} MAP snippets: {}'.format(prefix, bioasq_snip_res['MAP snippets']))\n",
    "    logger.info('{} GMAP snippets: {}'.format(prefix, bioasq_snip_res['GMAP snippets']))\n",
    "    #\n",
    "    return bioasq_snip_res\n",
    "\n",
    "def get_one_map(prefix, data, docs, use_sent_tokenizer):\n",
    "    model.eval()\n",
    "    #\n",
    "    ret_data                        = {'questions': []}\n",
    "    all_bioasq_subm_data_v1         = {\"questions\": []}\n",
    "    all_bioasq_subm_data_known_v1   = {\"questions\": []}\n",
    "    all_bioasq_subm_data_v2         = {\"questions\": []}\n",
    "    all_bioasq_subm_data_known_v2   = {\"questions\": []}\n",
    "    all_bioasq_subm_data_v3         = {\"questions\": []}\n",
    "    all_bioasq_subm_data_known_v3   = {\"questions\": []}\n",
    "    all_bioasq_gold_data            = {'questions': []}\n",
    "    data_for_revision               = {}\n",
    "    #\n",
    "    for dato in tqdm(data['queries']):\n",
    "        all_bioasq_gold_data['questions'].append(bioasq7_data[dato['query_id']])\n",
    "        data_for_revision, ret_data, snips_res, snips_res_known = do_for_some_retrieved(docs, dato, dato['retrieved_documents'], data_for_revision, ret_data, use_sent_tokenizer)\n",
    "        all_bioasq_subm_data_v1['questions'].append(snips_res['v1'])\n",
    "        all_bioasq_subm_data_v2['questions'].append(snips_res['v2'])\n",
    "        all_bioasq_subm_data_v3['questions'].append(snips_res['v3'])\n",
    "        all_bioasq_subm_data_known_v1['questions'].append(snips_res_known['v1'])\n",
    "        all_bioasq_subm_data_known_v2['questions'].append(snips_res_known['v3'])\n",
    "        all_bioasq_subm_data_known_v3['questions'].append(snips_res_known['v3'])\n",
    "    #\n",
    "    v1_bioasq_snip_res = print_the_results('v1 '+prefix, all_bioasq_gold_data, all_bioasq_subm_data_v1, all_bioasq_subm_data_known_v1, data_for_revision)\n",
    "    v2_bioasq_snip_res = print_the_results('v2 '+prefix, all_bioasq_gold_data, all_bioasq_subm_data_v2, all_bioasq_subm_data_known_v2, data_for_revision)\n",
    "    v3_bioasq_snip_res = print_the_results('v3 '+prefix, all_bioasq_gold_data, all_bioasq_subm_data_v3, all_bioasq_subm_data_known_v3, data_for_revision)\n",
    "    #\n",
    "    '''\n",
    "    if (prefix == 'dev'):\n",
    "        with open(os.path.join(odir, 'elk_relevant_abs_posit_drmm_lists_dev.json'), 'w') as f:\n",
    "            f.write(json.dumps(ret_data, indent=4, sort_keys=True))\n",
    "        res_map = get_map_res(\n",
    "            os.path.join(odir, 'v3 dev_gold_bioasq.json'),\n",
    "            # dataloc +'bioasq.dev.json',\n",
    "            os.path.join(odir, 'elk_relevant_abs_posit_drmm_lists_dev.json')\n",
    "        )\n",
    "    else:\n",
    "        with open(os.path.join(odir,'elk_relevant_abs_posit_drmm_lists_test.json'), 'w') as f:\n",
    "            f.write(json.dumps(ret_data, indent=4, sort_keys=True))\n",
    "        res_map = get_map_res(\n",
    "            os.path.join(odir, 'v3 test_gold_bioasq.json'),\n",
    "            os.path.join(odir, 'elk_relevant_abs_posit_drmm_lists_test.json')\n",
    "        )\n",
    "    return res_map\n",
    "    '''\n",
    "    return v3_bioasq_snip_res['MAP documents']\n",
    "\n",
    "def load_all_data(dataloc, w2v_bin_path, idf_pickle_path):\n",
    "    print('loading pickle data')\n",
    "    #\n",
    "    with open(dataloc+'trainining7b.json', 'r') as f:\n",
    "        bioasq7_data = json.load(f)\n",
    "        bioasq7_data = dict((q['id'], q) for q in bioasq7_data['questions'])\n",
    "    #\n",
    "    with open(dataloc + 'bioasq7_bm25_top100.dev.pkl', 'rb') as f:\n",
    "        dev_data = pickle.load(f)\n",
    "    with open(dataloc + 'bioasq7_bm25_docset_top100.dev.pkl', 'rb') as f:\n",
    "        dev_docs = pickle.load(f)\n",
    "    with open(dataloc + 'bioasq7_bm25_top100.train.pkl', 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(dataloc + 'bioasq7_bm25_docset_top100.train.pkl', 'rb') as f:\n",
    "        train_docs = pickle.load(f)\n",
    "    print('loading words')\n",
    "    #\n",
    "    words               = {}\n",
    "    GetWords(train_data, train_docs, words)\n",
    "    GetWords(dev_data,   dev_docs,   words)\n",
    "    #\n",
    "    print('loading idfs')\n",
    "    idf, max_idf    = load_idfs(idf_pickle_path, words)\n",
    "    print('loading w2v')\n",
    "    wv              = KeyedVectors.load_word2vec_format(w2v_bin_path, binary=True)\n",
    "    wv              = dict([(word, wv[word]) for word in wv.vocab.keys() if(word in words)])\n",
    "    return dev_data, dev_docs, train_data, train_docs, idf, max_idf, wv, bioasq7_data\n",
    "\n",
    "class Sent_Posit_Drmm_Modeler(nn.Module):\n",
    "    def __init__(self,\n",
    "             embedding_dim          = 30,\n",
    "             k_for_maxpool          = 5,\n",
    "             sentence_out_method    = 'MLP',\n",
    "             k_sent_maxpool         = 1\n",
    "         ):\n",
    "        super(Sent_Posit_Drmm_Modeler, self).__init__()\n",
    "        self.k                                      = k_for_maxpool\n",
    "        self.k_sent_maxpool                         = k_sent_maxpool\n",
    "        self.doc_add_feats                          = 11\n",
    "        self.sent_add_feats                         = 10\n",
    "        #\n",
    "        self.embedding_dim                          = embedding_dim\n",
    "        self.sentence_out_method                    = sentence_out_method\n",
    "        # to create q weights\n",
    "        self.init_context_module()\n",
    "        self.init_question_weight_module()\n",
    "        self.init_mlps_for_pooled_attention()\n",
    "        self.init_sent_output_layer()\n",
    "        self.init_doc_out_layer()\n",
    "        # doc loss func\n",
    "        self.margin_loss        = nn.MarginRankingLoss(margin=1.0)\n",
    "        if(use_cuda):\n",
    "            self.margin_loss    = self.margin_loss.cuda()\n",
    "    def init_mesh_module(self):\n",
    "        self.mesh_h0    = autograd.Variable(torch.randn(1, 1, self.embedding_dim))\n",
    "        self.mesh_gru   = nn.GRU(self.embedding_dim, self.embedding_dim)\n",
    "        if(use_cuda):\n",
    "            self.mesh_h0    = self.mesh_h0.cuda()\n",
    "            self.mesh_gru   = self.mesh_gru.cuda()\n",
    "    def init_context_module(self):\n",
    "        self.trigram_conv_1             = nn.Conv1d(self.embedding_dim, self.embedding_dim, 3, padding=2, bias=True)\n",
    "        # self.trigram_conv_activation_1  = torch.nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.trigram_conv_activation_1 = torch.nn.Sigmoid()\n",
    "        self.trigram_conv_2             = nn.Conv1d(self.embedding_dim, self.embedding_dim, 3, padding=2, bias=True)\n",
    "        # self.trigram_conv_activation_2  = torch.nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.trigram_conv_activation_2 = torch.nn.Sigmoid()\n",
    "        if(use_cuda):\n",
    "            self.trigram_conv_1             = self.trigram_conv_1.cuda()\n",
    "            self.trigram_conv_2             = self.trigram_conv_2.cuda()\n",
    "            self.trigram_conv_activation_1  = self.trigram_conv_activation_1.cuda()\n",
    "            self.trigram_conv_activation_2  = self.trigram_conv_activation_2.cuda()\n",
    "    def init_question_weight_module(self):\n",
    "        self.q_weights_mlp      = nn.Linear(self.embedding_dim+1, 1, bias=True)\n",
    "        if(use_cuda):\n",
    "            self.q_weights_mlp  = self.q_weights_mlp.cuda()\n",
    "    def init_mlps_for_pooled_attention(self):\n",
    "        self.linear_per_q1      = nn.Linear(3 * 3, 8, bias=True)\n",
    "        self.my_relu1           = torch.nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.linear_per_q2      = nn.Linear(8, 1, bias=True)\n",
    "        if(use_cuda):\n",
    "            self.linear_per_q1  = self.linear_per_q1.cuda()\n",
    "            self.linear_per_q2  = self.linear_per_q2.cuda()\n",
    "            self.my_relu1       = self.my_relu1.cuda()\n",
    "    def init_sent_output_layer(self):\n",
    "        if(self.sentence_out_method == 'MLP'):\n",
    "            self.sent_out_layer_1       = nn.Linear(self.sent_add_feats+1, 8, bias=False)\n",
    "            self.sent_out_activ_1       = torch.nn.LeakyReLU(negative_slope=0.1)\n",
    "            self.sent_out_layer_2       = nn.Linear(8, 1, bias=False)\n",
    "            if(use_cuda):\n",
    "                self.sent_out_layer_1   = self.sent_out_layer_1.cuda()\n",
    "                self.sent_out_activ_1   = self.sent_out_activ_1.cuda()\n",
    "                self.sent_out_layer_2   = self.sent_out_layer_2.cuda()\n",
    "        else:\n",
    "            self.sent_res_h0    = autograd.Variable(torch.randn(2, 1, 5))\n",
    "            self.sent_res_bigru = nn.GRU(input_size=self.sent_add_feats+1, hidden_size=5, bidirectional=True, batch_first=False)\n",
    "            self.sent_res_mlp   = nn.Linear(10, 1, bias=False)\n",
    "            if(use_cuda):\n",
    "                self.sent_res_h0    = self.sent_res_h0.cuda()\n",
    "                self.sent_res_bigru = self.sent_res_bigru.cuda()\n",
    "                self.sent_res_mlp   = self.sent_res_mlp.cuda()\n",
    "    def init_doc_out_layer(self):\n",
    "        self.final_layer_1 = nn.Linear(self.doc_add_feats+self.k_sent_maxpool, 8, bias=True)\n",
    "        self.final_activ_1  = torch.nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.final_layer_2  = nn.Linear(8, 1, bias=True)\n",
    "        self.oo_layer       = nn.Linear(2, 1, bias=True)\n",
    "        if(use_cuda):\n",
    "            self.final_layer_1  = self.final_layer_1.cuda()\n",
    "            self.final_activ_1  = self.final_activ_1.cuda()\n",
    "            self.final_layer_2  = self.final_layer_2.cuda()\n",
    "            self.oo_layer       = self.oo_layer.cuda()\n",
    "    def my_hinge_loss(self, positives, negatives, margin=1.0):\n",
    "        delta      = negatives - positives\n",
    "        loss_q_pos = torch.sum(F.relu(margin + delta), dim=-1)\n",
    "        return loss_q_pos\n",
    "    def apply_context_gru(self, the_input, h0):\n",
    "        output, hn      = self.context_gru(the_input.unsqueeze(1), h0)\n",
    "        output          = self.context_gru_activation(output)\n",
    "        out_forward     = output[:, 0, :self.embedding_dim]\n",
    "        out_backward    = output[:, 0, self.embedding_dim:]\n",
    "        output          = out_forward + out_backward\n",
    "        res             = output + the_input\n",
    "        return res, hn\n",
    "    def apply_context_convolution(self, the_input, the_filters, activation):\n",
    "        conv_res        = the_filters(the_input.transpose(0,1).unsqueeze(0))\n",
    "        if(activation is not None):\n",
    "            conv_res    = activation(conv_res)\n",
    "        pad             = the_filters.padding[0]\n",
    "        ind_from        = int(np.floor(pad/2.0))\n",
    "        ind_to          = ind_from + the_input.size(0)\n",
    "        conv_res        = conv_res[:, :, ind_from:ind_to]\n",
    "        conv_res        = conv_res.transpose(1, 2)\n",
    "        # residual\n",
    "        conv_res = conv_res + the_input\n",
    "        return conv_res.squeeze(0)\n",
    "    def my_cosine_sim(self, A, B):\n",
    "        A           = A.unsqueeze(0)\n",
    "        B           = B.unsqueeze(0)\n",
    "        A_mag       = torch.norm(A, 2, dim=2)\n",
    "        B_mag       = torch.norm(B, 2, dim=2)\n",
    "        num         = torch.bmm(A, B.transpose(-1,-2))\n",
    "        den         = torch.bmm(A_mag.unsqueeze(-1), B_mag.unsqueeze(-1).transpose(-1,-2))\n",
    "        dist_mat    = num / den\n",
    "        return dist_mat\n",
    "    def pooling_method(self, sim_matrix):\n",
    "        sorted_res              = torch.sort(sim_matrix, -1)[0]                             # sort the input minimum to maximum\n",
    "        k_max_pooled            = sorted_res[:,-self.k:]                                    # select the last k of each instance in our data\n",
    "        average_k_max_pooled    = k_max_pooled.sum(-1)/float(self.k)                        # average these k values\n",
    "        the_maximum             = k_max_pooled[:, -1]                                       # select the maximum value of each instance\n",
    "        the_average_over_all    = sorted_res.sum(-1)/float(sim_matrix.size(1))              # add average of all elements as long sentences might have more matches\n",
    "        the_concatenation       = torch.stack([the_maximum, average_k_max_pooled, the_average_over_all], dim=-1)  # concatenate maximum value and average of k-max values\n",
    "        return the_concatenation     # return the concatenation\n",
    "    def get_output(self, input_list, weights):\n",
    "        temp    = torch.cat(input_list, -1)\n",
    "        lo      = self.linear_per_q1(temp)\n",
    "        lo      = self.my_relu1(lo)\n",
    "        lo      = self.linear_per_q2(lo)\n",
    "        lo      = lo.squeeze(-1)\n",
    "        lo      = lo * weights\n",
    "        sr      = lo.sum(-1) / lo.size(-1)\n",
    "        return sr\n",
    "    def apply_sent_res_bigru(self, the_input):\n",
    "        output, hn      = self.sent_res_bigru(the_input.unsqueeze(1), self.sent_res_h0)\n",
    "        output          = self.sent_res_mlp(output)\n",
    "        return output.squeeze(-1).squeeze(-1)\n",
    "    def do_for_one_doc_cnn(self, doc_sents_embeds, sents_af, question_embeds, q_conv_res_trigram, q_weights, k2):\n",
    "        res = []\n",
    "        for i in range(len(doc_sents_embeds)):\n",
    "            sent_embeds         = autograd.Variable(torch.FloatTensor(doc_sents_embeds[i]), requires_grad=False)\n",
    "            gaf                 = autograd.Variable(torch.FloatTensor(sents_af[i]), requires_grad=False)\n",
    "            if(use_cuda):\n",
    "                sent_embeds     = sent_embeds.cuda()\n",
    "                gaf             = gaf.cuda()\n",
    "            conv_res            = self.apply_context_convolution(sent_embeds,   self.trigram_conv_1, self.trigram_conv_activation_1)\n",
    "            conv_res            = self.apply_context_convolution(conv_res,      self.trigram_conv_2, self.trigram_conv_activation_2)\n",
    "            #\n",
    "            sim_insens          = self.my_cosine_sim(question_embeds, sent_embeds).squeeze(0)\n",
    "            sim_oh              = (sim_insens > (1 - (1e-3))).float()\n",
    "            sim_sens            = self.my_cosine_sim(q_conv_res_trigram, conv_res).squeeze(0)\n",
    "            #\n",
    "            insensitive_pooled  = self.pooling_method(sim_insens)\n",
    "            sensitive_pooled    = self.pooling_method(sim_sens)\n",
    "            oh_pooled           = self.pooling_method(sim_oh)\n",
    "            #\n",
    "            sent_emit           = self.get_output([oh_pooled, insensitive_pooled, sensitive_pooled], q_weights)\n",
    "            sent_add_feats      = torch.cat([gaf, sent_emit.unsqueeze(-1)])\n",
    "            res.append(sent_add_feats)\n",
    "        res = torch.stack(res)\n",
    "        if(self.sentence_out_method == 'MLP'):\n",
    "            res = self.sent_out_layer_1(res)\n",
    "            res = self.sent_out_activ_1(res)\n",
    "            res = self.sent_out_layer_2(res).squeeze(-1)\n",
    "        else:\n",
    "            res = self.apply_sent_res_bigru(res)\n",
    "        # ret = self.get_max(res).unsqueeze(0)\n",
    "        ret = self.get_kmax(res, k2)\n",
    "        return ret, res\n",
    "    def do_for_one_doc_bigru(self, doc_sents_embeds, sents_af, question_embeds, q_conv_res_trigram, q_weights, k2):\n",
    "        res = []\n",
    "        hn  = self.context_h0\n",
    "        for i in range(len(doc_sents_embeds)):\n",
    "            sent_embeds         = autograd.Variable(torch.FloatTensor(doc_sents_embeds[i]), requires_grad=False)\n",
    "            gaf                 = autograd.Variable(torch.FloatTensor(sents_af[i]), requires_grad=False)\n",
    "            if(use_cuda):\n",
    "                sent_embeds     = sent_embeds.cuda()\n",
    "                gaf             = gaf.cuda()\n",
    "            conv_res, hn        = self.apply_context_gru(sent_embeds, hn)\n",
    "            #\n",
    "            sim_insens          = self.my_cosine_sim(question_embeds, sent_embeds).squeeze(0)\n",
    "            sim_oh              = (sim_insens > (1 - (1e-3))).float()\n",
    "            sim_sens            = self.my_cosine_sim(q_conv_res_trigram, conv_res).squeeze(0)\n",
    "            #\n",
    "            insensitive_pooled  = self.pooling_method(sim_insens)\n",
    "            sensitive_pooled    = self.pooling_method(sim_sens)\n",
    "            oh_pooled           = self.pooling_method(sim_oh)\n",
    "            #\n",
    "            sent_emit           = self.get_output([oh_pooled, insensitive_pooled, sensitive_pooled], q_weights)\n",
    "            sent_add_feats      = torch.cat([gaf, sent_emit.unsqueeze(-1)])\n",
    "            res.append(sent_add_feats)\n",
    "        res = torch.stack(res)\n",
    "        if(self.sentence_out_method == 'MLP'):\n",
    "            res = self.sent_out_layer_1(res)\n",
    "            res = self.sent_out_activ_1(res)\n",
    "            res = self.sent_out_layer_2(res).squeeze(-1)\n",
    "        else:\n",
    "            res = self.apply_sent_res_bigru(res)\n",
    "        # ret = self.get_max(res).unsqueeze(0)\n",
    "        ret = self.get_kmax(res, k2)\n",
    "        res = torch.sigmoid(res)\n",
    "        return ret, res\n",
    "    def get_max(self, res):\n",
    "        return torch.max(res)\n",
    "    def get_kmax(self, res, k):\n",
    "        res     = torch.sort(res,0)[0]\n",
    "        res     = res[-k:].squeeze(-1)\n",
    "        if(len(res.size())==0):\n",
    "            res = res.unsqueeze(0)\n",
    "        if(res.size()[0] < k):\n",
    "            to_concat       = torch.zeros(k - res.size()[0])\n",
    "            if(use_cuda):\n",
    "                to_concat   = to_concat.cuda()\n",
    "            res             = torch.cat([res, to_concat], -1)\n",
    "        return res\n",
    "    def get_max_and_average_of_k_max(self, res, k):\n",
    "        k_max_pooled            = self.get_kmax(res, k)\n",
    "        average_k_max_pooled    = k_max_pooled.sum()/float(k)\n",
    "        the_maximum             = k_max_pooled[-1]\n",
    "        the_concatenation       = torch.cat([the_maximum, average_k_max_pooled.unsqueeze(0)])\n",
    "        return the_concatenation\n",
    "    def get_average(self, res):\n",
    "        res = torch.sum(res) / float(res.size()[0])\n",
    "        return res\n",
    "    def get_maxmin_max(self, res):\n",
    "        res = self.min_max_norm(res)\n",
    "        res = torch.max(res)\n",
    "        return res\n",
    "    def apply_mesh_gru(self, mesh_embeds):\n",
    "        mesh_embeds             = autograd.Variable(torch.FloatTensor(mesh_embeds), requires_grad=False)\n",
    "        if(use_cuda):\n",
    "            mesh_embeds         = mesh_embeds.cuda()\n",
    "        output, hn              = self.mesh_gru(mesh_embeds.unsqueeze(1), self.mesh_h0)\n",
    "        return output[-1,0,:]\n",
    "    def get_mesh_rep(self, meshes_embeds, q_context):\n",
    "        meshes_embeds   = [self.apply_mesh_gru(mesh_embeds) for mesh_embeds in meshes_embeds]\n",
    "        meshes_embeds   = torch.stack(meshes_embeds)\n",
    "        sim_matrix      = self.my_cosine_sim(meshes_embeds, q_context).squeeze(0)\n",
    "        max_sim         = torch.sort(sim_matrix, -1)[0][:, -1]\n",
    "        output          = torch.mm(max_sim.unsqueeze(0), meshes_embeds)[0]\n",
    "        return output\n",
    "    def emit_one(self, doc1_sents_embeds, question_embeds, q_idfs, sents_gaf, doc_gaf):\n",
    "        q_idfs              = autograd.Variable(torch.FloatTensor(q_idfs),              requires_grad=False)\n",
    "        question_embeds     = autograd.Variable(torch.FloatTensor(question_embeds),     requires_grad=False)\n",
    "        doc_gaf             = autograd.Variable(torch.FloatTensor(doc_gaf),             requires_grad=False)\n",
    "        if(use_cuda):\n",
    "            q_idfs          = q_idfs.cuda()\n",
    "            question_embeds = question_embeds.cuda()\n",
    "            doc_gaf         = doc_gaf.cuda()\n",
    "        #\n",
    "        q_context           = self.apply_context_convolution(question_embeds,   self.trigram_conv_1, self.trigram_conv_activation_1)\n",
    "        q_context           = self.apply_context_convolution(q_context,         self.trigram_conv_2, self.trigram_conv_activation_2)\n",
    "        #\n",
    "        q_weights           = torch.cat([q_context, q_idfs], -1)\n",
    "        q_weights           = self.q_weights_mlp(q_weights).squeeze(-1)\n",
    "        q_weights           = F.softmax(q_weights, dim=-1)\n",
    "        #\n",
    "        good_out, gs_emits  = self.do_for_one_doc_cnn(doc1_sents_embeds, sents_gaf, question_embeds, q_context, q_weights, self.k_sent_maxpool)\n",
    "        #\n",
    "        good_out_pp         = torch.cat([good_out, doc_gaf], -1)\n",
    "        #\n",
    "        final_good_output   = self.final_layer_1(good_out_pp)\n",
    "        final_good_output   = self.final_activ_1(final_good_output)\n",
    "        final_good_output   = self.final_layer_2(final_good_output)\n",
    "        #\n",
    "        gs_emits            = gs_emits.unsqueeze(-1)\n",
    "        gs_emits            = torch.cat([gs_emits, final_good_output.unsqueeze(-1).expand_as(gs_emits)], -1)\n",
    "        gs_emits            = self.oo_layer(gs_emits).squeeze(-1)\n",
    "        gs_emits            = torch.sigmoid(gs_emits)\n",
    "        #\n",
    "        return final_good_output, gs_emits\n",
    "    def forward(self, doc1_sents_embeds, doc2_sents_embeds, question_embeds, q_idfs, sents_gaf, sents_baf, doc_gaf, doc_baf):\n",
    "        q_idfs              = autograd.Variable(torch.FloatTensor(q_idfs),              requires_grad=False)\n",
    "        question_embeds     = autograd.Variable(torch.FloatTensor(question_embeds),     requires_grad=False)\n",
    "        doc_gaf             = autograd.Variable(torch.FloatTensor(doc_gaf),             requires_grad=False)\n",
    "        doc_baf             = autograd.Variable(torch.FloatTensor(doc_baf),             requires_grad=False)\n",
    "        if(use_cuda):\n",
    "            q_idfs          = q_idfs.cuda()\n",
    "            question_embeds = question_embeds.cuda()\n",
    "            doc_gaf         = doc_gaf.cuda()\n",
    "            doc_baf         = doc_baf.cuda()\n",
    "        #\n",
    "        q_context           = self.apply_context_convolution(question_embeds,   self.trigram_conv_1, self.trigram_conv_activation_1)\n",
    "        q_context           = self.apply_context_convolution(q_context,         self.trigram_conv_2, self.trigram_conv_activation_2)\n",
    "        #\n",
    "        q_weights           = torch.cat([q_context, q_idfs], -1)\n",
    "        q_weights           = self.q_weights_mlp(q_weights).squeeze(-1)\n",
    "        q_weights           = F.softmax(q_weights, dim=-1)\n",
    "        #\n",
    "        good_out, gs_emits  = self.do_for_one_doc_cnn(doc1_sents_embeds, sents_gaf, question_embeds, q_context, q_weights, self.k_sent_maxpool)\n",
    "        bad_out, bs_emits   = self.do_for_one_doc_cnn(doc2_sents_embeds, sents_baf, question_embeds, q_context, q_weights, self.k_sent_maxpool)\n",
    "        #\n",
    "        good_out_pp         = torch.cat([good_out, doc_gaf], -1)\n",
    "        bad_out_pp          = torch.cat([bad_out, doc_baf], -1)\n",
    "        #\n",
    "        final_good_output   = self.final_layer_1(good_out_pp)\n",
    "        final_good_output   = self.final_activ_1(final_good_output)\n",
    "        final_good_output   = self.final_layer_2(final_good_output)\n",
    "        #\n",
    "        gs_emits            = gs_emits.unsqueeze(-1)\n",
    "        gs_emits            = torch.cat([gs_emits, final_good_output.unsqueeze(-1).expand_as(gs_emits)], -1)\n",
    "        gs_emits            = self.oo_layer(gs_emits).squeeze(-1)\n",
    "        gs_emits            = torch.sigmoid(gs_emits)\n",
    "        #\n",
    "        final_bad_output    = self.final_layer_1(bad_out_pp)\n",
    "        final_bad_output    = self.final_activ_1(final_bad_output)\n",
    "        final_bad_output    = self.final_layer_2(final_bad_output)\n",
    "        #\n",
    "        bs_emits            = bs_emits.unsqueeze(-1)\n",
    "        # bs_emits            = torch.cat([bs_emits, final_good_output.unsqueeze(-1).expand_as(bs_emits)], -1)\n",
    "        bs_emits            = torch.cat([bs_emits, final_bad_output.unsqueeze(-1).expand_as(bs_emits)], -1)\n",
    "        bs_emits            = self.oo_layer(bs_emits).squeeze(-1)\n",
    "        bs_emits            = torch.sigmoid(bs_emits)\n",
    "        #\n",
    "        loss1               = self.my_hinge_loss(final_good_output, final_bad_output)\n",
    "        return loss1, final_good_output, final_bad_output, gs_emits, bs_emits\n",
    "\n",
    "\n",
    "def load_model_from_checkpoint(resume_from):\n",
    "    global start_epoch, optimizer\n",
    "    if os.path.isfile(resume_from):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume_from))\n",
    "        checkpoint = torch.load(resume_from, map_location=lambda storage, loc: storage)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume_from, checkpoint['epoch']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "##########################################\n",
    "eval_path           = r'D:\\aueb-bioasq7-master\\Evaluation\\eval\\run_eval.py'\n",
    "retrieval_jar_path  = r'D:\\aueb-bioasq7-master\\Evaluation\\dist\\my_bioasq_eval_2.jar'\n",
    "odd                 = r'D:\\aueb-bioasq7-master\\Outputs\\odd\\\\'\n",
    "##########################################\n",
    "w2v_bin_path                = './Data/PretrainedWeightsAndVectors/pubmed2018_w2v_30D.bin'\n",
    "idf_pickle_path             = './Data/PretrainedWeightsAndVectors/idf.pkl'\n",
    "dataloc             = './Data/bioasq_data/'\n",
    "resume_from                 = './Data/bioasq_jpdrmm_2L_0p01_run_0/best_dev_checkpoint.pth.tar'\n",
    "##########################################\n",
    "# eval_path           = '/content/drive/My Drive/data_for_colab/bioasq7/eval (1)/run_eval.py'\n",
    "# retrieval_jar_path  = '/content/drive/My Drive/data_for_colab/bioasq7/dist/my_bioasq_eval_2.jar'\n",
    "# odd                 = '/content/drive/My Drive/data_for_colab/bioasq7/outputs/'\n",
    "##########################################\n",
    "# w2v_bin_path    = '/content/drive/My Drive/data_for_colab/pubmed2018_w2v_30D.bin'\n",
    "# idf_pickle_path = '/content/drive/My Drive/data_for_colab/idf.pkl'\n",
    "# dataloc         = '/content/drive/My Drive/data_for_colab/bioasq7/data/'\n",
    "##########################################\n",
    "(\n",
    "    dev_data, dev_docs,\n",
    "    train_data, train_docs,\n",
    "    idf, max_idf,\n",
    "    wv, bioasq7_data\n",
    ") = load_all_data(dataloc, w2v_bin_path, idf_pickle_path)\n",
    "##########################################\n",
    "avgdl, mean, deviation = get_bm25_metrics(avgdl=21.1907, mean=0.6275, deviation=1.2210)\n",
    "print(avgdl, mean, deviation)\n",
    "##########################################\n",
    "\n",
    "k_for_maxpool       = 5\n",
    "k_sent_maxpool      = 5\n",
    "embedding_dim       = 30 #200\n",
    "lr                  = 0.01\n",
    "b_size              = 32\n",
    "max_epoch           = 30\n",
    "early_stop          = 25\n",
    "\n",
    "import sys\n",
    "# run_from    = int(sys.argv[1])\n",
    "# run_to      = int(sys.argv[2])\n",
    "run_from    = 0\n",
    "run_to      = 1\n",
    "hdlr        = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(run_from, run_to):\n",
    "    #\n",
    "    my_seed = run\n",
    "    random.seed(my_seed)\n",
    "    torch.manual_seed(my_seed)\n",
    "    #\n",
    "    odir    = 'bioasq_jpdrmm_test_{}/'.format(run)\n",
    "    odir    = os.path.join(odd, odir)\n",
    "    print(odir)\n",
    "    if(not os.path.exists(odir)):\n",
    "        os.makedirs(odir)\n",
    "    #\n",
    "    logger, hdlr    = init_the_logger(hdlr)\n",
    "    print('random seed: {}'.format(my_seed))\n",
    "    logger.info('random seed: {}'.format(my_seed))\n",
    "    #\n",
    "    print('Compiling model...')\n",
    "    logger.info('Compiling model...')\n",
    "    model       = Sent_Posit_Drmm_Modeler(embedding_dim=embedding_dim, k_for_maxpool=k_for_maxpool)\n",
    "    if(use_cuda):\n",
    "        model   = model.cuda()\n",
    "    params      = model.parameters()\n",
    "    print_params(model)\n",
    "    load_model_from_checkpoint(resume_from)\n",
    "    optimizer   = optim.Adam(params, lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "    #\n",
    "    waited_for  = 0\n",
    "    best_dev_map, test_map = None, None\n",
    "    for epoch in range(max_epoch):\n",
    "        train_one(epoch+1, bioasq7_data, two_losses=True, use_sent_tokenizer=True)\n",
    "        epoch_dev_map       = get_one_map('dev', dev_data, dev_docs, use_sent_tokenizer=True)\n",
    "        if(best_dev_map is None or epoch_dev_map>=best_dev_map):\n",
    "            best_dev_map    = epoch_dev_map\n",
    "            # test_map        = get_one_map('test', test_data, all_docs, use_sent_tokenizer=True)\n",
    "            save_checkpoint(epoch, model, best_dev_map, optimizer, filename=os.path.join(odir, 'best_dev_checkpoint.pth.tar'))\n",
    "            waited_for = 0\n",
    "        else:\n",
    "            waited_for += 1\n",
    "        print('epoch: {:02d} epoch_dev_map: {:.4f} best_dev_map: {:.4f}'.format(epoch + 1, epoch_dev_map, best_dev_map))\n",
    "        logger.info('epoch: {:02d} epoch_dev_map: {:.4f} best_dev_map: {:.4f}'.format(epoch + 1, epoch_dev_map, best_dev_map))\n",
    "        if (waited_for > early_stop):\n",
    "            print('early stop in epoch {} . waited for {} epochs'.format(epoch, early_stop))\n",
    "            logger.info('early stop in epoch {} . waited for {} epochs'.format(epoch, early_stop))\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "29,041,002 articles\n",
    "29,017,626 with title\n",
    "18,707,863 with abstract as well \n",
    "\n",
    "Is Hirschsprung disease a mendelian or a multifactorial disorder\n",
    "\n",
    "search: _exists_:AbstractText AND AbstractText:/.+/ AND _exists_:ArticleTitle AND ArticleTitle:/.+/\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=1 python3.6\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "#####################\n",
    "bioasq7_data        = json.load(open(os.path.join(dataloc,   'trainining7b.json')))\n",
    "bioasq7_data        = dict((q['id'], q) for q in bioasq7_data['questions'])\n",
    "all_docs            = pickle.load(open(os.path.join(dataloc, 'bioasq_bm25_docset_top100.all.pkl'), 'rb'))\n",
    "all_data            = pickle.load(open(os.path.join(dataloc, 'bioasq_bm25_top100.all.pkl'), 'rb'))\n",
    "#####################\n",
    "train_data          = {'queries': all_data['queries'][:-100]}\n",
    "dev_data            = {'queries': all_data['queries'][-100:]}\n",
    "#####################\n",
    "train_data          = RemoveBadYears(train_data, all_docs, True)\n",
    "train_data          = RemoveTrainLargeYears(train_data, all_docs)\n",
    "dev_data            = RemoveBadYears(dev_data, all_docs, False)\n",
    "#####################\n",
    "words               = {}\n",
    "GetWords(all_data, all_docs, words)\n",
    "#####################\n",
    "print('loading idfs')\n",
    "idf, max_idf        = load_idfs(idf_pickle_path, words)\n",
    "print('loading w2v')\n",
    "wv                  = KeyedVectors.load_word2vec_format(w2v_bin_path, binary=True)\n",
    "wv                  = dict([(word, wv[word]) for word in wv.vocab.keys() if (word in words)])\n",
    "'''\n",
    "\n",
    "'''\n",
    "# # atlas , cslab243\n",
    "# w2v_bin_path        = '/home/dpappas/bioasq_all/pubmed2018_w2v_30D.bin'\n",
    "# idf_pickle_path     = '/home/dpappas/bioasq_all/idf.pkl'\n",
    "# # dataloc             = '/home/dpappas/bioasq_all/bioasq_data/'\n",
    "# # dataloc             = '/home/dpappas/bioasq_all/for_ryan_clean/'\n",
    "# dataloc             = '/home/dpappas/bioasq_all/for_ryan_clean_2/'\n",
    "# eval_path           = '/home/dpappas/bioasq_all/eval/run_eval.py'\n",
    "# retrieval_jar_path  = '/home/dpappas/bioasq_all/dist/my_bioasq_eval_2.jar'\n",
    "# odd                 = '/home/dpappas/'\n",
    "# use_cuda            = True\n",
    "\n",
    "# # thundera\n",
    "# w2v_bin_path        = '/home/dpappas/bioasq_all/pubmed2018_w2v_30D.bin'\n",
    "# idf_pickle_path     = '/home/dpappas/bioasq_all/idf.pkl'\n",
    "# dataloc             = '/home/dpappas/bioasq_all/for_ryan_clean/'\n",
    "# eval_path           = '/home/dpappas/dpappas/bioasq_all/eval/run_eval.py'\n",
    "# retrieval_jar_path  = '/home/dpappas/bioasq_all/dist/my_bioasq_eval_2.jar'\n",
    "# odd                 = '/home/cave-of-time/dpappas/model_outputs/'\n",
    "'''\n",
    "\n",
    "'''\n",
    "! java -Xmx10G -cp \\\n",
    "\"/content/drive/My Drive/data_for_colab/bioasq7/dist/my_bioasq_eval_2.jar\" \\\n",
    "evaluation.EvaluatorTask1b -phaseA -e 5 \\\n",
    "\"/content/drive/My Drive/data_for_colab/bioasq7/outputs/bioasq_jpdrmm_2L_0p01_run_0/v3 dev_gold_bioasq.json\" \\\n",
    "\"/content/drive/My Drive/data_for_colab/bioasq7/outputs/bioasq_jpdrmm_2L_0p01_run_0/v3 dev_emit_bioasq.json\"\n",
    "\n",
    "! python \\\n",
    "\"/content/drive/My Drive/data_for_colab/bioasq7/eval (1)/run_eval.py\" \\\n",
    "\"/content/drive/My Drive/data_for_colab/bioasq7/outputs/bioasq_jpdrmm_2L_0p01_run_0/v3 dev_gold_bioasq.json\" \\\n",
    "\"/content/drive/My Drive/data_for_colab/bioasq7/outputs/bioasq_jpdrmm_2L_0p01_run_0/v3 dev_emit_bioasq.json\"\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "np.average([len(q['snippets']) for q in list(bioasq7_data.values())])\n",
    "list(bioasq7_data.values())[0].keys()\n",
    "np.average([len(q['relevant_documents']) for q in train_data['queries']])\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
